{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 12 Building Parsimonious Models - Individual - [25 points] - Solutions\n",
    "\n",
    "\n",
    "## <u>Case Study</u>: Creating an Classifer Model that will Accurately Predict whether an Instagram Account is Fake or Real *with New Data*\n",
    "\n",
    "We will revisit the fake_insta_cleaned.csv dataset one more time. In this case, we would like to build a **parsimonious** logistic regression model that predicts the probability that an account is fake. To help us find this parsimonious model we will consider all of the other remaining variables as potential explanatory variables to include in the model.\n",
    "\n",
    "* the number of accounts someone *follows*\n",
    "* number of *followers*\n",
    "* number of posts\n",
    "* number of words in name\n",
    "* number of characters in the bio\n",
    "* whether they have a profile picture or not\n",
    "\n",
    "We will use the following two methods to help us find a parsimonious model.\n",
    "1. Backward Elimination Algorithm with AIC score \n",
    "2. Regularized Logistic Regression\n",
    "\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "<table style=\"border: none;border-collapse: collapse;width:102pt;\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:700;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:general;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;width:51pt;\">Problem</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:700;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:general;vertical-align:bottom;border:.5pt solid windowtext;border-left:none;width:51pt;\">Points</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">2.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">4</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">5.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">6.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">6.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">7.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">7.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">7.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.5</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.6</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.7</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.8</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">8.9</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function seaborn.rcmod.set(*args, **kwargs)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "sns.set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preliminaries\n",
    "### 1.1  Read the fake_insta_cleaned.csv into a dataframe called df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_insta_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>account_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>488</td>\n",
       "      <td>604</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>319</td>\n",
       "      <td>328</td>\n",
       "      <td>668</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>356</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>362</td>\n",
       "      <td>424</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "0               yes                        1                     30   \n",
       "1               yes                        5                     64   \n",
       "2               yes                        2                     82   \n",
       "3               yes                        1                     76   \n",
       "4               yes                        1                      0   \n",
       "\n",
       "   number_of_posts  number_of_followers  number_of_follows account_type  \n",
       "0               35                  488                604         real  \n",
       "1                3                   35                  6         real  \n",
       "2              319                  328                668         real  \n",
       "3                6                  225                356         real  \n",
       "4                6                  362                424         real  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.  Next, create a new variable y in df that is equal to 1 when the the account is fake and that is equal to 0 when the account is real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>account_type</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>488</td>\n",
       "      <td>604</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>319</td>\n",
       "      <td>328</td>\n",
       "      <td>668</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>356</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>362</td>\n",
       "      <td>424</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>114</td>\n",
       "      <td>811</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>164</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>833</td>\n",
       "      <td>3572</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>1695</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>68</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "0                 yes                        1                     30   \n",
       "1                 yes                        5                     64   \n",
       "2                 yes                        2                     82   \n",
       "3                 yes                        1                     76   \n",
       "4                 yes                        1                      0   \n",
       "..                ...                      ...                    ...   \n",
       "107               yes                        1                      0   \n",
       "108               yes                        1                      0   \n",
       "109               yes                        2                      0   \n",
       "110                no                        1                      0   \n",
       "111               yes                        1                      0   \n",
       "\n",
       "     number_of_posts  number_of_followers  number_of_follows account_type  y  \n",
       "0                 35                  488                604         real  0  \n",
       "1                  3                   35                  6         real  0  \n",
       "2                319                  328                668         real  0  \n",
       "3                  6                  225                356         real  0  \n",
       "4                  6                  362                424         real  0  \n",
       "..               ...                  ...                ...          ... ..  \n",
       "107               13                  114                811         fake  1  \n",
       "108                4                  150                164         fake  1  \n",
       "109                3                  833               3572         fake  1  \n",
       "110                1                  219               1695         fake  1  \n",
       "111                3                   39                 68         fake  1  \n",
       "\n",
       "[112 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'] = df['account_type'].map({'fake': 1, 'real': 0})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training and Test Data\n",
    "\n",
    "First, we want to create a training dataset to train the dataset and a test dataset to test the model's performance.\n",
    "\n",
    "### 2.1. First, create a training dataset and a test dataset where:\n",
    "* the training dataset is comprised of a random sample of 85% of the rows in our dataframe,\n",
    "* the test dataset is comprised of the remaining 15% of rows in the dataframe, and\n",
    "* we use a random state of 456."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size =0.15, random_state = 456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>account_type</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>114</td>\n",
       "      <td>811</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>386</td>\n",
       "      <td>363</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>276</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>463</td>\n",
       "      <td>2267</td>\n",
       "      <td>466</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>145</td>\n",
       "      <td>573</td>\n",
       "      <td>474</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>55</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>118</td>\n",
       "      <td>461</td>\n",
       "      <td>1055</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>238</td>\n",
       "      <td>1381</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>366</td>\n",
       "      <td>552</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "107               yes                        1                      0   \n",
       "47                yes                        1                     13   \n",
       "19                yes                        1                      0   \n",
       "38                yes                        2                     77   \n",
       "52                yes                        2                    146   \n",
       "..                ...                      ...                    ...   \n",
       "42                yes                        2                      0   \n",
       "89                yes                        1                      0   \n",
       "43                yes                        2                     18   \n",
       "101               yes                        1                      0   \n",
       "27                yes                        2                      0   \n",
       "\n",
       "     number_of_posts  number_of_followers  number_of_follows account_type  y  \n",
       "107               13                  114                811         fake  1  \n",
       "47                14                  386                363         real  0  \n",
       "19                 0                  189                276         real  0  \n",
       "38               463                 2267                466         real  0  \n",
       "52               145                  573                474         real  0  \n",
       "..               ...                  ...                ...          ... ..  \n",
       "42                 0                   87                 40         real  0  \n",
       "89                81                   75                 55         fake  1  \n",
       "43               118                  461               1055         real  0  \n",
       "101               60                  238               1381         fake  1  \n",
       "27                 9                  366                552         real  0  \n",
       "\n",
       "[95 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Full Model\n",
    "\n",
    "Next, we would like for our 'full model' to predict the probability that an account is fake, using ALL of the following available explanatory variables.\n",
    "* the number of accounts someone *follows*\n",
    "* number of *followers*\n",
    "* number of posts\n",
    "* number of words in name\n",
    "* number of characters in the bio\n",
    "* whether they have a profile picture or not\n",
    "\n",
    "### 3.1. Fit the full model with all six of these explanatory variables using just your *training dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.122645\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    88</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 16 Nov 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.8227</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:58:44</td>     <th>  Log-Likelihood:    </th> <td> -11.651</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th> <td> -65.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>5.015e-21</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>  106.9158</td> <td>  1.2e+05</td> <td>    0.001</td> <td> 0.999</td> <td>-2.35e+05</td> <td> 2.35e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_a_profile_pic[T.yes]</th> <td> -101.7707</td> <td>  1.2e+05</td> <td>   -0.001</td> <td> 0.999</td> <td>-2.35e+05</td> <td> 2.35e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_follows</th>        <td>    0.0098</td> <td>    0.003</td> <td>    3.168</td> <td> 0.002</td> <td>    0.004</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_followers</th>      <td>   -0.0299</td> <td>    0.010</td> <td>   -3.107</td> <td> 0.002</td> <td>   -0.049</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_posts</th>          <td>    0.0084</td> <td>    0.009</td> <td>    0.973</td> <td> 0.331</td> <td>   -0.009</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_words_in_name</th>  <td>   -1.4222</td> <td>    0.621</td> <td>   -2.290</td> <td> 0.022</td> <td>   -2.640</td> <td>   -0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_characters_in_bio</th>    <td>   -0.1171</td> <td>    0.053</td> <td>   -2.201</td> <td> 0.028</td> <td>   -0.221</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.52 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   95\n",
       "Model:                          Logit   Df Residuals:                       88\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Tue, 16 Nov 2021   Pseudo R-squ.:                  0.8227\n",
       "Time:                        19:58:44   Log-Likelihood:                -11.651\n",
       "converged:                      False   LL-Null:                       -65.717\n",
       "Covariance Type:            nonrobust   LLR p-value:                 5.015e-21\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                  106.9158    1.2e+05      0.001      0.999   -2.35e+05    2.35e+05\n",
       "has_a_profile_pic[T.yes]  -101.7707    1.2e+05     -0.001      0.999   -2.35e+05    2.35e+05\n",
       "number_of_follows            0.0098      0.003      3.168      0.002       0.004       0.016\n",
       "number_of_followers         -0.0299      0.010     -3.107      0.002      -0.049      -0.011\n",
       "number_of_posts              0.0084      0.009      0.973      0.331      -0.009       0.025\n",
       "number_of_words_in_name     -1.4222      0.621     -2.290      0.022      -2.640      -0.205\n",
       "num_characters_in_bio       -0.1171      0.053     -2.201      0.028      -0.221      -0.013\n",
       "============================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.52 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullmod = smf.logit('y~number_of_follows+number_of_followers+number_of_posts+number_of_words_in_name+num_characters_in_bio+has_a_profile_pic', data = df_train).fit()\n",
    "fullmod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.    Backwards Elimination\n",
    "\n",
    "Next, starting with the full model, use a backwards elimination algorithm that seeks to find the model with the lowest **AIC** score. You should fit each of these models in the algorithm with *just the training dataset*. Once the algorithm has stopped, print out the summary output of your **final model**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['has_a_profile_pic', 'number_of_words_in_name', 'num_characters_in_bio',\n",
       "       'number_of_posts', 'number_of_followers', 'number_of_follows',\n",
       "       'account_type', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.122645\n",
      "         Iterations: 35\n",
      "Current Mod AIC:  37.302469591041266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "curr_mod = smf.logit('y~number_of_follows+number_of_followers+number_of_posts+number_of_words_in_name+num_characters_in_bio+has_a_profile_pic', data = df_train).fit()\n",
    "print('Current Mod AIC: ', curr_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.329550\n",
      "         Iterations 9\n",
      "Test Mod AIC:  74.6145407668493\n"
     ]
    }
   ],
   "source": [
    "#delete has_a_profile_pic[T.yes]\n",
    "test_mod = smf.logit('y~number_of_follows+number_of_followers+number_of_posts+number_of_words_in_name+num_characters_in_bio', data = df_train).fit()\n",
    "print('Test Mod AIC: ', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.206117\n",
      "         Iterations: 35\n",
      "Test Mod AIC:  51.16232420711868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "#delete num_characters_in_bio\n",
    "test_mod = smf.logit('y~number_of_follows+number_of_followers+number_of_posts+number_of_words_in_name+has_a_profile_pic', data = df_train).fit()\n",
    "print('Test Mod AIC: ', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.150957\n",
      "         Iterations: 35\n",
      "Test Mod AIC:  40.68191132258672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "#delete number_of_words_in_name\n",
    "test_mod = smf.logit('y~number_of_follows+number_of_followers+number_of_posts+num_characters_in_bio+has_a_profile_pic', data = df_train).fit()\n",
    "print('Test Mod AIC: ', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.125481\n",
      "         Iterations: 35\n",
      "Test Mod AIC:  35.84137144664035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "#delete number_of_posts\n",
    "test_mod = smf.logit('y~number_of_follows+number_of_followers+number_of_words_in_name+num_characters_in_bio+has_a_profile_pic', data = df_train).fit()\n",
    "print('Test Mod AIC: ', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.276135\n",
      "         Iterations: 35\n",
      "Test Mod AIC:  64.46572563330452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "#delete number_of_followers\n",
    "test_mod = smf.logit('y~number_of_follows+number_of_posts+number_of_words_in_name+num_characters_in_bio+has_a_profile_pic', data = df_train).fit()\n",
    "print('Test Mod AIC: ', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.331365\n",
      "         Iterations: 35\n",
      "Test Mod AIC:  74.95943769115172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "#delete number_of_follows\n",
    "test_mod = smf.logit('y~number_of_followers+number_of_posts+number_of_words_in_name+num_characters_in_bio+has_a_profile_pic', data = df_train).fit()\n",
    "print('Test Mod AIC: ', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.343064\n",
      "         Iterations 9\n",
      "Test Mod AIC:  75.1822506514567\n"
     ]
    }
   ],
   "source": [
    "#delete number_of_posts + has_a_profile_pic\n",
    "test_mod = smf.logit('y~number_of_follows+number_of_followers+number_of_words_in_name+num_characters_in_bio', data = df_train).fit()\n",
    "print('Test Mod AIC: ', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.223078\n",
      "         Iterations: 35\n",
      "Test Mod AIC:  52.38490360992095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "#delete number_of_posts + num_characters_in_bio\n",
    "test_mod = smf.logit('y~number_of_follows+number_of_followers+number_of_words_in_name+has_a_profile_pic', data = df_train).fit()\n",
    "print('Test Mod AIC: ', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.152157\n",
      "         Iterations: 35\n",
      "Test Mod AIC:  38.909752825917934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "#delete number_of_posts + number_of_words_in_name\n",
    "test_mod = smf.logit('y~number_of_follows+number_of_followers+num_characters_in_bio+has_a_profile_pic', data = df_train).fit()\n",
    "print('Test Mod AIC: ', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.286734\n",
      "         Iterations: 35\n",
      "Test Mod AIC:  64.47943290808563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "#delete number_of_posts + number_of_followers\n",
    "test_mod = smf.logit('y~number_of_follows+number_of_words_in_name+num_characters_in_bio+has_a_profile_pic', data = df_train).fit()\n",
    "print('Test Mod AIC: ', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.344200\n",
      "         Iterations: 35\n",
      "Test Mod AIC:  75.39806057027377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "#delete number_of_posts + number_of_follows\n",
    "test_mod = smf.logit('y~number_of_followers+number_of_words_in_name+num_characters_in_bio+has_a_profile_pic', data = df_train).fit()\n",
    "print('Test Mod AIC: ', test_mod.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.125481\n",
      "         Iterations: 35\n",
      "Final Mod AIC:  35.84137144664035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    89</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 16 Nov 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.8186</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:58:45</td>     <th>  Log-Likelihood:    </th> <td> -11.921</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th> <td> -65.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.321e-21</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>  103.9262</td> <td> 2.29e+05</td> <td>    0.000</td> <td> 1.000</td> <td> -4.5e+05</td> <td>  4.5e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_a_profile_pic[T.yes]</th> <td>  -98.8981</td> <td> 2.29e+05</td> <td>   -0.000</td> <td> 1.000</td> <td> -4.5e+05</td> <td>  4.5e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_follows</th>        <td>    0.0093</td> <td>    0.003</td> <td>    3.211</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_followers</th>      <td>   -0.0284</td> <td>    0.009</td> <td>   -3.146</td> <td> 0.002</td> <td>   -0.046</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_words_in_name</th>  <td>   -1.3617</td> <td>    0.606</td> <td>   -2.246</td> <td> 0.025</td> <td>   -2.550</td> <td>   -0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_characters_in_bio</th>    <td>   -0.1060</td> <td>    0.050</td> <td>   -2.141</td> <td> 0.032</td> <td>   -0.203</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.51 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   95\n",
       "Model:                          Logit   Df Residuals:                       89\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Tue, 16 Nov 2021   Pseudo R-squ.:                  0.8186\n",
       "Time:                        19:58:45   Log-Likelihood:                -11.921\n",
       "converged:                      False   LL-Null:                       -65.717\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.321e-21\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                  103.9262   2.29e+05      0.000      1.000    -4.5e+05     4.5e+05\n",
       "has_a_profile_pic[T.yes]   -98.8981   2.29e+05     -0.000      1.000    -4.5e+05     4.5e+05\n",
       "number_of_follows            0.0093      0.003      3.211      0.001       0.004       0.015\n",
       "number_of_followers         -0.0284      0.009     -3.146      0.002      -0.046      -0.011\n",
       "number_of_words_in_name     -1.3617      0.606     -2.246      0.025      -2.550      -0.173\n",
       "num_characters_in_bio       -0.1060      0.050     -2.141      0.032      -0.203      -0.009\n",
       "============================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.51 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mod = smf.logit('y~number_of_follows+number_of_followers+number_of_words_in_name+num_characters_in_bio+has_a_profile_pic', data = df_train).fit()\n",
    "print('Final Mod AIC: ', final_mod.aic)\n",
    "final_mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parsimonious Model Evaluation\n",
    "\n",
    "### 5.1.   Compare the BIC score from your final model (from #4) to your full model (from #3). Use the BIC score to assess which of these models is more of a parsimonious model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.179607832245054"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullmod.bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.164632796243595"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mod.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is more parsimonious because it has a lower BIC compared to the BIC of the full model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. More About Models\n",
    "\n",
    "### 6.1.   Considering the six possible explanatory variables we *could* include in a logistic regression, how many possible logistic regression models could we create with this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create 6 possible logistic regresssion models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.   Which of the following logistic regression models would be *less likely* to be overfit the model (using the training data)? Explain.\n",
    "a. A model that predicts fake accounts using: number_of_followers and number_of_follows? \n",
    "\n",
    "b. A model that predicts fake accounts using: num_characters_in_bio and number_of_words_in_name? \n",
    "\n",
    "- highest llg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.592487\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    92</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 16 Nov 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.1435</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:58:45</td>     <th>  Log-Likelihood:    </th> <td> -56.286</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -65.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>8.020e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td>    0.4552</td> <td>    0.291</td> <td>    1.564</td> <td> 0.118</td> <td>   -0.115</td> <td>    1.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_follows</th>   <td>    0.0011</td> <td>    0.000</td> <td>    2.785</td> <td> 0.005</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_followers</th> <td>   -0.0028</td> <td>    0.001</td> <td>   -2.860</td> <td> 0.004</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   95\n",
       "Model:                          Logit   Df Residuals:                       92\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Tue, 16 Nov 2021   Pseudo R-squ.:                  0.1435\n",
       "Time:                        19:58:45   Log-Likelihood:                -56.286\n",
       "converged:                       True   LL-Null:                       -65.717\n",
       "Covariance Type:            nonrobust   LLR p-value:                 8.020e-05\n",
       "=======================================================================================\n",
       "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Intercept               0.4552      0.291      1.564      0.118      -0.115       1.026\n",
       "number_of_follows       0.0011      0.000      2.785      0.005       0.000       0.002\n",
       "number_of_followers    -0.0028      0.001     -2.860      0.004      -0.005      -0.001\n",
       "=======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_mod = smf.logit('y~number_of_follows+number_of_followers', data = df_train).fit()\n",
    "a_mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.424546\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    92</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 16 Nov 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.3863</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:58:45</td>     <th>  Log-Likelihood:    </th> <td> -40.332</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -65.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>9.446e-12</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>    1.9773</td> <td>    0.574</td> <td>    3.445</td> <td> 0.001</td> <td>    0.852</td> <td>    3.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_characters_in_bio</th>   <td>   -0.0858</td> <td>    0.027</td> <td>   -3.127</td> <td> 0.002</td> <td>   -0.140</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_words_in_name</th> <td>   -0.6340</td> <td>    0.361</td> <td>   -1.756</td> <td> 0.079</td> <td>   -1.342</td> <td>    0.073</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   95\n",
       "Model:                          Logit   Df Residuals:                       92\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Tue, 16 Nov 2021   Pseudo R-squ.:                  0.3863\n",
       "Time:                        19:58:45   Log-Likelihood:                -40.332\n",
       "converged:                       True   LL-Null:                       -65.717\n",
       "Covariance Type:            nonrobust   LLR p-value:                 9.446e-12\n",
       "===========================================================================================\n",
       "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                   1.9773      0.574      3.445      0.001       0.852       3.102\n",
       "num_characters_in_bio      -0.0858      0.027     -3.127      0.002      -0.140      -0.032\n",
       "number_of_words_in_name    -0.6340      0.361     -1.756      0.079      -1.342       0.073\n",
       "===========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_mod = smf.logit('y~num_characters_in_bio+number_of_words_in_name', data = df_train).fit()\n",
    "b_mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model b would be less likely to overfit the model because it has a higher Log-Likelihood compared to model A. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Testing\n",
    "\n",
    "Finally, we would like to test our \"final model\" (from 4) on the **test dataset**.\n",
    "\n",
    "### 7.1.   Plot the ROC and calculate the AUC for the \"final model\" (from 4) with the *test dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/y82mj0c50414t7pxpf1ygz840000gn/T/ipykernel_30481/2345002274.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['p_hat'] = p_hat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>account_type</th>\n",
       "      <th>y</th>\n",
       "      <th>p_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>488</td>\n",
       "      <td>604</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>510</td>\n",
       "      <td>185</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>64</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>0.952902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>356</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>415</td>\n",
       "      <td>1445</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "0                yes                        1                     30   \n",
       "36               yes                        0                     47   \n",
       "75               yes                        1                      0   \n",
       "3                yes                        1                     76   \n",
       "99                no                        1                    112   \n",
       "\n",
       "    number_of_posts  number_of_followers  number_of_follows account_type  y  \\\n",
       "0                35                  488                604         real  0   \n",
       "36                2                  510                185         real  0   \n",
       "75                0                   45                 64         fake  1   \n",
       "3                 6                  225                356         real  0   \n",
       "99                4                  415               1445         fake  1   \n",
       "\n",
       "       p_hat  \n",
       "0   0.000291  \n",
       "36  0.000001  \n",
       "75  0.952902  \n",
       "3   0.000236  \n",
       "99  1.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hat = fullmod.predict(exog = df_test)\n",
    "df_test['p_hat'] = p_hat\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "fpr_pew, tpr_pew, score_pew = roc_curve(y_true = df_test['y'], y_score = df_test['p_hat'])\n",
    "auc_pew = roc_auc_score(y_true = df_test['y'], y_score = df_test['p_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, auc, lw = 2):\n",
    "    plt.plot(fpr, tpr, color = 'darkorange', lw = lw, label = 'ROC curve (area = '+str(round(auc, 3))+')')\n",
    "    plt.plot([0,1], [0,1], color = 'navy', lw = lw, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fullmod_roc = plot_roc(fpr_pew, tpr_pew, auc_pew)\n",
    "fullmod_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC is 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.    How effective will this model be at classifying Instagram accounts in the *test dataset*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will be very effective at classifying Instagram accounts in the test dataset because the AUC is 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.   Finally, find a predictive probability threshold that will give you the \"best\" false positive rate and true positive rate for the *test dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   threshold  tpr  fpr\n",
      "0        0.0  1.0  1.0\n",
      "   threshold  tpr       fpr\n",
      "0       0.01  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.02  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.03  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.04  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.05  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.06  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.07  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.08  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.09  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0        0.1  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.11  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.12  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.13  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.14  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.15  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.16  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.17  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.18  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.19  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0        0.2  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.21  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.22  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.23  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.24  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.25  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.26  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.27  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.28  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.29  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0        0.3  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.31  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.32  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.33  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.34  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.35  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.36  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.37  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.38  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.39  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0        0.4  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.41  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.42  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.43  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.44  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.45  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.46  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.47  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.48  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.49  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0        0.5  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.51  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.52  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.53  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.54  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.55  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.56  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.57  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.58  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.59  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0        0.6  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.61  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.62  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.63  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.64  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.65  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.66  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.67  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.68  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.69  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0        0.7  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.71  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.72  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.73  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.74  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.75  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.76  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.77  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.78  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.79  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0        0.8  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.81  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.82  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.83  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.84  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.85  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.86  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.87  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.88  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.89  1.0  0.111111\n",
      "   threshold  tpr  fpr\n",
      "0        0.9  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.91  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.92  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.93  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.94  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.95  1.0  0.0\n",
      "   threshold    tpr  fpr\n",
      "0       0.96  0.875  0.0\n",
      "   threshold    tpr  fpr\n",
      "0       0.97  0.875  0.0\n",
      "   threshold    tpr  fpr\n",
      "0       0.98  0.875  0.0\n",
      "   threshold   tpr  fpr\n",
      "0       0.99  0.75  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def tpr_fpr_thresh(y, pred_prob, thresh):\n",
    "    yhat = 1*(pred_prob >= thresh)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=y, y_pred=yhat).ravel()\n",
    "    tpr = tp / (fn + tp)\n",
    "    fpr = fp / (fp + tn)\n",
    "    return pd.DataFrame({'threshold':[thresh],\n",
    "                         'tpr':[tpr], \n",
    "                         'fpr':[fpr]})\n",
    "tpr_fpr_thresh(df_test['y'],df_test['p_hat'], 0.5)\n",
    "\n",
    "for thresh in np.arange(0,1, 0.01): \n",
    "    print (tpr_fpr_thresh(df_test['y'],df_test['p_hat'], thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictive probability threshold that will give the best fpr and tpr of (0.0, 1.0) is from 0.90 to 0.95."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Regularized Logistic Regression\n",
    "\n",
    "Next, we would also like to use regularized logistic regression as a way to select potential reduced models that may be more parsimonious than the full model.\n",
    "\n",
    "### 8.1. Explanatory Variables Dataframe\n",
    "\n",
    "First, create a dataframe that is comprised of the six possible explanatory variables in your **training dataset**. Any categorical variables (with $w$ levels) in your training dataframe should be represented as $w-1$ 0/1 indicator variables in this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>114</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>386</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>463</td>\n",
       "      <td>2267</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>145</td>\n",
       "      <td>573</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "107               yes                        1                      0   \n",
       "47                yes                        1                     13   \n",
       "19                yes                        1                      0   \n",
       "38                yes                        2                     77   \n",
       "52                yes                        2                    146   \n",
       "\n",
       "     number_of_posts  number_of_followers  number_of_follows  \n",
       "107               13                  114                811  \n",
       "47                14                  386                363  \n",
       "19                 0                  189                276  \n",
       "38               463                 2267                466  \n",
       "52               145                  573                474  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_train.drop(columns = ['y', 'account_type'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Response Variable Series\n",
    "\n",
    "Next, create a pandas series that is comprised of your 0/1 response variable in the **training dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107    1\n",
       "47     0\n",
       "19     0\n",
       "38     0\n",
       "52     0\n",
       "      ..\n",
       "42     0\n",
       "89     1\n",
       "43     0\n",
       "101    1\n",
       "27     0\n",
       "Name: y, Length: 95, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X, drop_first = True)\n",
    "X.head()\n",
    "y = df_train['y']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3. Non-Regularized Logistic Regression\n",
    "\n",
    "Next, fit a non-regularized logistic regression model using the following specifications:\n",
    "* Use the newton-cg optimization solver.\n",
    "* Have this optimization algorithm use up to 2000 iterations when solving for the optimal values of $\\hat{\\beta}_0, \\hat{\\beta}_1,...,\\hat{\\beta}_6$.\n",
    "\n",
    "After fitting the model, display the slopes for this non-regularized logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000, penalty='none', solver='newton-cg')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf0 = LogisticRegression(penalty = 'none', solver = 'newton-cg', max_iter = 2000)\n",
    "clf0.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.42174274e+00, -1.17092738e-01,  8.42434180e-03,\n",
       "        -2.98939167e-02,  9.84256730e-03, -8.82766869e+01]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf0.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4. LASSO Logistic Regression\n",
    "\n",
    "Next, fit a LASSO logistic regression model using the following specifications:\n",
    "* Use the liblinear optimization solver.\n",
    "* Have this optimization algorithm use up to 2000 iterations when solving for the optimal values of $\\hat{\\beta}_0, \\hat{\\beta}_1,...,\\hat{\\beta}_6$.\n",
    "* Use a value of $\\lambda=10$.\n",
    "\n",
    "After fitting the model, display the slopes for this LASSO logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=2000, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = LogisticRegression(penalty = 'l1', solver = 'liblinear', max_iter = 2000, C = 1/10)\n",
    "clf1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.09351871, -0.00968396, -0.00064215,  0.00203836,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5. Ridge Logistic Regression\n",
    "\n",
    "Next, fit a ridge logistic regression model using the following specifications:\n",
    "* Use the newton-cg optimization solver.\n",
    "* Have this optimization algorithm use up to 2000 iterations when solving for the optimal values of $\\hat{\\beta}_0, \\hat{\\beta}_1,...,\\hat{\\beta}_6$.\n",
    "* Use a value of $\\lambda=10$.\n",
    "\n",
    "After fitting the model, display the slopes for this ridge logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=2000, solver='newton-cg')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(penalty = 'l2', solver = 'newton-cg', max_iter = 2000, C = 1/10)\n",
    "clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.29191761, -0.09993136, -0.01822698, -0.00111281,  0.00142097,\n",
       "        -0.38556254]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6. Elastic Net Logistic Regression\n",
    "\n",
    "Next, fit an elastic net logistic regression model using the following specifications:\n",
    "* Use the saga optimization solver.\n",
    "* Have this optimization algorithm use up to 2000 iterations when solving for the optimal values of $\\hat{\\beta}_0, \\hat{\\beta}_1,...,\\hat{\\beta}_6$.\n",
    "* Use a value of $\\lambda=10$.\n",
    "* **We would like to choose from either using $\\alpha=0.25$ or $\\alpha=0.75$ to use in this elastic net model. Use the value of $\\alpha$ which will encourage the values of $\\hat{\\beta}_0, \\hat{\\beta}_1,...,\\hat{\\beta}_6$ to look like more of what we would get if we were using a logistic ridge regression model.**\n",
    "\n",
    "After fitting the model, display the slopes for this elastic net logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a = 0.25 because it is closer to 0, so the solutions will be more likely to resemble a logisitic ridge regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, l1_ratio=0.25, max_iter=2000, penalty='elasticnet',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = LogisticRegression(penalty = 'elasticnet', solver = 'saga', max_iter = 2000, l1_ratio = 0.25, C= 1/10)\n",
    "clf3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.99421188e-06, -2.05403014e-02, -1.59075971e-02,\n",
       "        -9.04483134e-04,  1.62735375e-03,  0.00000000e+00]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7. Finding Another Prospective Reduced Model\n",
    "\n",
    "Let's use the results of our LASSO model to help us determine one final reduced model to try out. Which explanatory variables are the LASSO model results suggesting should unambiguously **not** be in a parsimonious model? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LASSO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <td>-0.093519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_posts</th>\n",
       "      <td>-0.009684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_followers</th>\n",
       "      <td>-0.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_follows</th>\n",
       "      <td>0.002038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_a_profile_pic_yes</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            LASSO\n",
       "number_of_words_in_name  0.000000\n",
       "num_characters_in_bio   -0.093519\n",
       "number_of_posts         -0.009684\n",
       "number_of_followers     -0.000642\n",
       "number_of_follows        0.002038\n",
       "has_a_profile_pic_yes    0.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coef = pd.DataFrame(clf1.coef_.T, columns = ['LASSO'], index = X.columns)\n",
    "lasso_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number_of_words_in_name and has_a_profile_pic_yes are the explanatory variables that should not be in a parsimonious model because their slopes are 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.8 Fit the New Reduced Model\n",
    "\n",
    "Fit a new reduced model (with the **training dataset**), leaving out the explanatory variables that were suggested to be left out by the LASSO model. Display the summary output table for this new reduced model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.350453\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    90</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 16 Nov 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.4934</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:58:47</td>     <th>  Log-Likelihood:    </th> <td> -33.293</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -65.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.769e-13</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>             <td>    1.2734</td> <td>    0.394</td> <td>    3.229</td> <td> 0.001</td> <td>    0.500</td> <td>    2.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_characters_in_bio</th> <td>   -0.1054</td> <td>    0.040</td> <td>   -2.643</td> <td> 0.008</td> <td>   -0.183</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_posts</th>       <td>   -0.0215</td> <td>    0.013</td> <td>   -1.644</td> <td> 0.100</td> <td>   -0.047</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_followers</th>   <td>   -0.0010</td> <td>    0.001</td> <td>   -1.427</td> <td> 0.154</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_follows</th>     <td>    0.0013</td> <td>    0.001</td> <td>    2.398</td> <td> 0.016</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.13 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   95\n",
       "Model:                          Logit   Df Residuals:                       90\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Tue, 16 Nov 2021   Pseudo R-squ.:                  0.4934\n",
       "Time:                        19:58:47   Log-Likelihood:                -33.293\n",
       "converged:                       True   LL-Null:                       -65.717\n",
       "Covariance Type:            nonrobust   LLR p-value:                 2.769e-13\n",
       "=========================================================================================\n",
       "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "Intercept                 1.2734      0.394      3.229      0.001       0.500       2.046\n",
       "num_characters_in_bio    -0.1054      0.040     -2.643      0.008      -0.183      -0.027\n",
       "number_of_posts          -0.0215      0.013     -1.644      0.100      -0.047       0.004\n",
       "number_of_followers      -0.0010      0.001     -1.427      0.154      -0.002       0.000\n",
       "number_of_follows         0.0013      0.001      2.398      0.016       0.000       0.002\n",
       "=========================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.13 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_mod = smf.logit('y~num_characters_in_bio+number_of_posts+number_of_followers+number_of_follows', data = df_train).fit()\n",
    "red_mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.9 Comparing BIC Scores\n",
    "\n",
    "Compare the BIC scores of the full model (ie. the model that uses all 6 possible explanatory variables) and this new reduced model. Which of these two models does the BIC score suggest is more parsimonious? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.179607832245054"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullmod.bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.35546293961194"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_mod.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BIC score suggests the full model is more parsimonious because it is lower compared to the BIC for the reduced model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
